{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgJGTlpoRto2exoeVPIB0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushsrinivas7/WebScraping/blob/main/webscraping_started1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL1bF00bS0TS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hey we use headers because we can ask server via browser only thats why we are using the header which has the browser details.\n"
      ],
      "metadata": {
        "id": "O7FXNPHiWHhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using the requests you will load the webpage . what you need is data so make it into text so that searching will be easy"
      ],
      "metadata": {
        "id": "Zx7SpUb-XYWB"
      }
    },
    {
      "source": [
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36',\n",
        "}\n",
        "url =\"https://www.ambitionbox.com/list-of-companies?page=1\"\n",
        "page = requests.get( url , headers = headers ).text"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "msuJvh6HUyMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now beautifulsoup is a class which will intake your text file and details regarding the file ('lxml' is used here )\n",
        "and will create a object which has many functions which can make tasks like searching , sorting and many other"
      ],
      "metadata": {
        "id": "zQqi03KtWGy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(page , 'lxml' )"
      ],
      "metadata": {
        "id": "bcJLCwflVJE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using find_all we are finding the html element we need . and .text will give the text in that html elemnt\n",
        ".strip() will remove all the extra spaces"
      ],
      "metadata": {
        "id": "btTDvbIoaI4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in soup.find_all('h2'):\n",
        "  print(i.text.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU7VbaofXyNU",
        "outputId": "a7a93cb9-b66a-49e9-eb2a-db3e6101f9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TCS\n",
            "Accenture\n",
            "Cognizant\n",
            "Wipro\n",
            "Capgemini\n",
            "HDFC Bank\n",
            "ICICI Bank\n",
            "Infosys\n",
            "HCLTech\n",
            "Tech Mahindra\n",
            "Genpact\n",
            "Axis Bank\n",
            "Teleperformance\n",
            "Concentrix Corporation\n",
            "Jio\n",
            "Amazon\n",
            "IBM\n",
            "Reliance Retail\n",
            "HDB Financial Services\n",
            "Larsen & Toubro Limited\n",
            "Companies by  Industry\n",
            "Companies by  Locations\n",
            "Companies by  Type\n",
            "Companies by  Badges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We go to the website and will do the instpection  then we will identify the things which we need and in which component it is there and what class it is there and based on that we will perform the activity  \n",
        "....... here the entire details about the comapnies comes in the div tag with class caompanycardwrapper . using that we willl get all trhe details of the commpanies .\n",
        "like that we need to find all the things that are needed\n",
        "**"
      ],
      "metadata": {
        "id": "QMntYt09oCPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "companies_details = soup.find_all('div' , class_ = \"companyCardWrapper\" )\n",
        "len(companies_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPgo9dntbK4U",
        "outputId": "3db292f1-08fe-4a48-f168-061b28d9fbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  this is finding detils for a single compny\n",
        "\n",
        "c1 = companies_details[0]\n",
        "\n",
        "cn =  c1.find('h2' , class_ = \"companyCardWrapper__companyName\").text.strip()\n",
        "crat = c1.find_all('span' , class_ = \"companyCardWrapper__companyRatingValue\")[0].text.strip()\n",
        "ch =   c1.find_all('span' , class_ = \"companyCardWrapper__ratingValues\" )[0].text.strip()\n",
        "cneg =   c1.find_all('span' , class_ = \"companyCardWrapper__ratingValues\" )[1].text.strip()\n",
        "rc =   c1.find_all('span' , class_ = \"companyCardWrapper__ActionCount\" )[0].text.strip()\n",
        "jc =   c1.find_all('span' , class_ = \"companyCardWrapper__ActionCount\" )[3].text.strip()\n",
        "\n",
        "\n",
        "#  see this for how we got the code for individual pices"
      ],
      "metadata": {
        "id": "hyRNYmCsfTe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EovCvrSXvgK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cname = []\n",
        "crating = []\n",
        "cpos= []\n",
        "cnegi =[]\n",
        "trev = []\n",
        "jb_cnt = []\n",
        "import numpy as np\n",
        "\n",
        "for i in range( 1 , 20):\n",
        "  url =\"https://www.ambitionbox.com/list-of-companies?page={}\".format(i)\n",
        "  headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36',\n",
        "     }\n",
        "  page = requests.get( url , headers = headers ).text\n",
        "  soup = BeautifulSoup(page , 'lxml' )\n",
        "  companies_details = soup.find_all('div' , class_ = \"companyCardWrapper\" )\n",
        "  print(len(companies_details))\n",
        "  for j in range(0 , len(companies_details) ):\n",
        "      c1 = companies_details[j]\n",
        "      try:\n",
        "        cname.append( c1.find('h2' , class_ = \"companyCardWrapper__companyName\").text.strip())\n",
        "      except:\n",
        "        cname.append(np.nan)\n",
        "      # rating\n",
        "      try:\n",
        "        crating.append(c1.find_all('span' , class_ = \"companyCardWrapper__companyRatingValue\")[0].text.strip() )\n",
        "      except:\n",
        "        crating.append(np.nan)\n",
        "      try:\n",
        "        cpos.append( c1.find_all('span' , class_ = \"companyCardWrapper__ratingValues\" )[0].text.strip())\n",
        "      except:\n",
        "        cpos.append(np.nan)\n",
        "      try:\n",
        "        cnegi.append(c1.find_all('span' , class_ = \"companyCardWrapper__ratingValues\" )[1].text.strip())\n",
        "      except:\n",
        "        cnegi.append(np.nan)\n",
        "      try:\n",
        "        trev.append(c1.find_all('span' , class_ = \"companyCardWrapper__ActionCount\" )[0].text.strip())\n",
        "      except:\n",
        "        trev.append(np.nan)\n",
        "      try:\n",
        "        jb_cnt.append( c1.find_all('span' , class_ = \"companyCardWrapper__ActionCount\" )[3].text.strip())\n",
        "      except:\n",
        "        jb_cnt.append(np.nan)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_TSPPiso9GV",
        "outputId": "c754ee56-a2ca-40b7-d26f-e48ef29bbfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame( {'name':cname , 'rating':crating  , 'postives' : cpos , 'negitives' : cnegi  , 'totalreview' : trev  , 'job_count' : jb_cnt })"
      ],
      "metadata": {
        "id": "PbSYBu4Jvhr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('companies_detils')"
      ],
      "metadata": {
        "id": "7cwrO3KwvQV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0hT5imLwm36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}